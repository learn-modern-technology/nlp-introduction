{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 class=\"alert alert-block alert-info\" style=\"text-align:center; font-size:30px\">Sentiment Analysis for Twitter Data</h1>","metadata":{}},{"cell_type":"markdown","source":"<h1 class=\"alert alert-block alert-info\" style=\"text-align:center; font-size:30px\">Problem Statement</h1>\n<li>Study the subjects of recent tweets about the vaccine made in collaboration by Pfizer and BioNTech, perform various NLP tasks on this data source\n","metadata":{}},{"cell_type":"markdown","source":"\n<h1 class=\"alert alert-block alert-info\" style=\"text-align:center; font-size:30px\">About Data Set</h1>\n<li>Data is collected from recent tweets about Pfizer and BioNTech vaccine.\n<li>The data is collected using tweepy Python package to access Twitter API.\n","metadata":{}},{"cell_type":"markdown","source":"\n<h1 class=\"alert alert-block alert-info\" style=\"text-align:center; font-size:30px\">Importing Libraries</h1>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-21T22:46:12.279479Z","iopub.execute_input":"2023-07-21T22:46:12.279988Z","iopub.status.idle":"2023-07-21T22:46:12.295744Z","shell.execute_reply.started":"2023-07-21T22:46:12.279950Z","shell.execute_reply":"2023-07-21T22:46:12.294407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For basic table operation\nimport pandas as pd\n\n#For work with arrays\nimport numpy as np\n\n#For find pattern in text\nimport re\n\n#For visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nstyle.use(\"ggplot\")\n\n#For processing textial data\nfrom textblob import TextBlob\n\n#For Tokenizing segments\nfrom nltk.tokenize import word_tokenize\n\n#For Stemming text\nfrom nltk.stem import PorterStemmer\n\n#For removing StopWords\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\n\n#For Plotting Words\nfrom wordcloud import WordCloud\n\n# Convert a collection of text documents to a matrix of token counts.\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n#To split data into train and test\nfrom sklearn.model_selection import train_test_split\n\n#For fitting model\nfrom sklearn.linear_model import LogisticRegression\n\n#For evaluation of model\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n\n#For Hyper-tuning model\nfrom sklearn.model_selection import GridSearchCV\n","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:12.298582Z","iopub.execute_input":"2023-07-21T22:46:12.299063Z","iopub.status.idle":"2023-07-21T22:46:12.309546Z","shell.execute_reply.started":"2023-07-21T22:46:12.299019Z","shell.execute_reply":"2023-07-21T22:46:12.308400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/pfizer-vaccine-tweets/vaccination_tweets.csv\")\ndf.head(4)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T23:20:20.417784Z","iopub.execute_input":"2023-07-21T23:20:20.418801Z","iopub.status.idle":"2023-07-21T23:20:20.553595Z","shell.execute_reply.started":"2023-07-21T23:20:20.418750Z","shell.execute_reply":"2023-07-21T23:20:20.552623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:12.453784Z","iopub.execute_input":"2023-07-21T22:46:12.454136Z","iopub.status.idle":"2023-07-21T22:46:12.499392Z","shell.execute_reply.started":"2023-07-21T22:46:12.454106Z","shell.execute_reply":"2023-07-21T22:46:12.497947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:12.501191Z","iopub.execute_input":"2023-07-21T22:46:12.501896Z","iopub.status.idle":"2023-07-21T22:46:12.509740Z","shell.execute_reply.started":"2023-07-21T22:46:12.501843Z","shell.execute_reply":"2023-07-21T22:46:12.508507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extracting only Text attributs for analysis\ntext_df = df.drop(['id', 'user_name', 'user_location', 'user_description', 'user_created',\n       'user_followers', 'user_friends', 'user_favourites', 'user_verified',\n       'date', 'hashtags', 'source', 'retweets', 'favorites',\n       'is_retweet'],axis=1)\ntext_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:12.512462Z","iopub.execute_input":"2023-07-21T22:46:12.512775Z","iopub.status.idle":"2023-07-21T22:46:12.527036Z","shell.execute_reply.started":"2023-07-21T22:46:12.512748Z","shell.execute_reply":"2023-07-21T22:46:12.525913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualizing Raw data we have from Tweetr\nprint(text_df[\"text\"].iloc[0],\"\\n\")\nprint(text_df[\"text\"].iloc[1],\"\\n\")\nprint(text_df[\"text\"].iloc[2],\"\\n\")\nprint(text_df[\"text\"].iloc[3],\"\\n\")\nprint(text_df[\"text\"].iloc[4],\"\\n\")\nprint(text_df[\"text\"].iloc[5],\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:12.528687Z","iopub.execute_input":"2023-07-21T22:46:12.529016Z","iopub.status.idle":"2023-07-21T22:46:12.537241Z","shell.execute_reply.started":"2023-07-21T22:46:12.528986Z","shell.execute_reply":"2023-07-21T22:46:12.535851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<h1 class=\"alert alert-block alert-info\" style=\"text-align:center; font-size:30px\">Data Preprocessing</h1>","metadata":{}},{"cell_type":"code","source":"def data_processing(text):\n    text = text.lower()     #Converting to text to lowercase\n    text = re.sub(r'https\\S+|www\\S+https\\S+','',text,flags=re.MULTILINE)   #Removing URL\n    text = re.sub(r'\\@w+|\\#','',text)         #Removing hashtags\n    text = re.sub(r'[^\\w\\s]','',text)         #Removing hashtags\n    text_tokens = word_tokenize(text)         #Getting tokens\n    filtered_text = [w for w in text_tokens if not w in stop_words]\n    return \" \".join(filtered_text)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:12.538467Z","iopub.execute_input":"2023-07-21T22:46:12.538786Z","iopub.status.idle":"2023-07-21T22:46:12.548017Z","shell.execute_reply.started":"2023-07-21T22:46:12.538760Z","shell.execute_reply":"2023-07-21T22:46:12.547199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying Data Processing function\ntext_df.text = text_df[\"text\"].apply(data_processing)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:12.550120Z","iopub.execute_input":"2023-07-21T22:46:12.550561Z","iopub.status.idle":"2023-07-21T22:46:15.564626Z","shell.execute_reply.started":"2023-07-21T22:46:12.550495Z","shell.execute_reply":"2023-07-21T22:46:15.563584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing Duplicates if any\ntext_df = text_df.drop_duplicates('text')","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:15.566054Z","iopub.execute_input":"2023-07-21T22:46:15.566413Z","iopub.status.idle":"2023-07-21T22:46:15.575475Z","shell.execute_reply.started":"2023-07-21T22:46:15.566362Z","shell.execute_reply":"2023-07-21T22:46:15.574407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Performing Stemming\nstemmer = PorterStemmer()\ndef stemming(data):\n    text = [stemmer.stem(word) for word in data]\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:15.576728Z","iopub.execute_input":"2023-07-21T22:46:15.577071Z","iopub.status.idle":"2023-07-21T22:46:15.586883Z","shell.execute_reply.started":"2023-07-21T22:46:15.577037Z","shell.execute_reply":"2023-07-21T22:46:15.585882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_df[\"text\"] = text_df[\"text\"].apply(lambda x: stemming(x))","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:15.591204Z","iopub.execute_input":"2023-07-21T22:46:15.591549Z","iopub.status.idle":"2023-07-21T22:46:16.284772Z","shell.execute_reply.started":"2023-07-21T22:46:15.591519Z","shell.execute_reply":"2023-07-21T22:46:16.283756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualizing Processed text\nprint(text_df[\"text\"].iloc[0],\"\\n\")\nprint(text_df[\"text\"].iloc[1],\"\\n\")\nprint(text_df[\"text\"].iloc[2],\"\\n\")\nprint(text_df[\"text\"].iloc[3],\"\\n\")\nprint(text_df[\"text\"].iloc[4],\"\\n\")\nprint(text_df[\"text\"].iloc[5],\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:16.286523Z","iopub.execute_input":"2023-07-21T22:46:16.287539Z","iopub.status.idle":"2023-07-21T22:46:16.297724Z","shell.execute_reply.started":"2023-07-21T22:46:16.287494Z","shell.execute_reply":"2023-07-21T22:46:16.296523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking data shape\nprint(\"Shape of data after processing:\",text_df[\"text\"].shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:16.299346Z","iopub.execute_input":"2023-07-21T22:46:16.299733Z","iopub.status.idle":"2023-07-21T22:46:16.311836Z","shell.execute_reply.started":"2023-07-21T22:46:16.299705Z","shell.execute_reply":"2023-07-21T22:46:16.309959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calculating polarity for categorizing text \ndef polarity(text):\n    return TextBlob(text).sentiment.polarity","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:16.313383Z","iopub.execute_input":"2023-07-21T22:46:16.313692Z","iopub.status.idle":"2023-07-21T22:46:16.320594Z","shell.execute_reply.started":"2023-07-21T22:46:16.313654Z","shell.execute_reply":"2023-07-21T22:46:16.319487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_df[\"polarity\"] = text_df[\"text\"].apply(polarity)\ntext_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:16.321603Z","iopub.execute_input":"2023-07-21T22:46:16.321881Z","iopub.status.idle":"2023-07-21T22:46:18.680153Z","shell.execute_reply.started":"2023-07-21T22:46:16.321855Z","shell.execute_reply":"2023-07-21T22:46:18.679018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  Adding Sentiment to the data frame\ndef sentiment(label):\n    if label <0:\n        return \"Negative\"\n    elif label ==0:\n        return \"Neutral\"\n    elif label>0:\n        return \"Positive\"","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:18.681438Z","iopub.execute_input":"2023-07-21T22:46:18.681816Z","iopub.status.idle":"2023-07-21T22:46:18.687623Z","shell.execute_reply.started":"2023-07-21T22:46:18.681790Z","shell.execute_reply":"2023-07-21T22:46:18.686466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_df['sentiment'] = text_df['polarity'].apply(sentiment)\ntext_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:18.688791Z","iopub.execute_input":"2023-07-21T22:46:18.689773Z","iopub.status.idle":"2023-07-21T22:46:18.717443Z","shell.execute_reply.started":"2023-07-21T22:46:18.689699Z","shell.execute_reply":"2023-07-21T22:46:18.716355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing the Sentiment\nfig = plt.figure(figsize=(7,5))\nsns.countplot(x=\"sentiment\",data=text_df)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:18.720096Z","iopub.execute_input":"2023-07-21T22:46:18.720497Z","iopub.status.idle":"2023-07-21T22:46:18.945829Z","shell.execute_reply.started":"2023-07-21T22:46:18.720459Z","shell.execute_reply":"2023-07-21T22:46:18.944780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(7,7))\ncolors = (\"yellowgreen\", \"gold\", \"red\")\nwp = {'linewidth':2, 'edgecolor':\"black\"}\ntags = text_df['sentiment'].value_counts()\nexplode = (0.1,0.1,0.1)\ntags.plot(kind='pie', autopct='%1.1f%%', shadow=True, colors = colors,\n         startangle=90, wedgeprops = wp, explode = explode, label='')\nplt.title('Distribution of sentiments')","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:18.947518Z","iopub.execute_input":"2023-07-21T22:46:18.948213Z","iopub.status.idle":"2023-07-21T22:46:19.171517Z","shell.execute_reply.started":"2023-07-21T22:46:18.948175Z","shell.execute_reply":"2023-07-21T22:46:19.169901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visulaizing Top 5 positive Sentiments\npos_tweets = text_df[text_df.sentiment == 'Positive']\npos_tweets = pos_tweets.sort_values(['polarity'], ascending= False)\npos_tweets.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:19.173630Z","iopub.execute_input":"2023-07-21T22:46:19.175089Z","iopub.status.idle":"2023-07-21T22:46:19.203333Z","shell.execute_reply.started":"2023-07-21T22:46:19.175009Z","shell.execute_reply":"2023-07-21T22:46:19.202041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = ' '.join([word for word in pos_tweets['text']])\nplt.figure(figsize=(20,15), facecolor='None')\nwordcloud = WordCloud(max_words=500, width=1600, height=800).generate(text)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title('Most frequent words in positive tweets', fontsize=19)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:19.205267Z","iopub.execute_input":"2023-07-21T22:46:19.206636Z","iopub.status.idle":"2023-07-21T22:46:25.121360Z","shell.execute_reply.started":"2023-07-21T22:46:19.206577Z","shell.execute_reply":"2023-07-21T22:46:25.120229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing Negative Words\nneg_tweets = text_df[text_df.sentiment == 'Negative']\nneg_tweets = neg_tweets.sort_values(['polarity'], ascending= False)\nneg_tweets.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:25.123047Z","iopub.execute_input":"2023-07-21T22:46:25.123719Z","iopub.status.idle":"2023-07-21T22:46:25.145565Z","shell.execute_reply.started":"2023-07-21T22:46:25.123681Z","shell.execute_reply":"2023-07-21T22:46:25.144521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = ' '.join([word for word in neg_tweets['text']])\nplt.figure(figsize=(20,15), facecolor='None')\nwordcloud = WordCloud(max_words=500, width=1600, height=800).generate(text)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title('Most frequent words in negative tweets', fontsize=19)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:25.147330Z","iopub.execute_input":"2023-07-21T22:46:25.147731Z","iopub.status.idle":"2023-07-21T22:46:30.678397Z","shell.execute_reply.started":"2023-07-21T22:46:25.147701Z","shell.execute_reply":"2023-07-21T22:46:30.677235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing Neutral Words\nneutral_tweets = text_df[text_df.sentiment == 'Neutral']\nneutral_tweets = neutral_tweets.sort_values(['polarity'], ascending= False)\nneutral_tweets.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:30.679814Z","iopub.execute_input":"2023-07-21T22:46:30.680135Z","iopub.status.idle":"2023-07-21T22:46:30.697214Z","shell.execute_reply.started":"2023-07-21T22:46:30.680108Z","shell.execute_reply":"2023-07-21T22:46:30.696071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = ' '.join([word for word in neutral_tweets['text']])\nplt.figure(figsize=(20,15), facecolor='None')\nwordcloud = WordCloud(max_words=500, width=1600, height=800).generate(text)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title('Most frequent words in neutral tweets', fontsize=19)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:30.698646Z","iopub.execute_input":"2023-07-21T22:46:30.699083Z","iopub.status.idle":"2023-07-21T22:46:36.800144Z","shell.execute_reply.started":"2023-07-21T22:46:30.699052Z","shell.execute_reply":"2023-07-21T22:46:36.798992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<h1 class=\"alert alert-block alert-info\" style=\"text-align:center; font-size:30px\">Vectorizing Data</h1>\n","metadata":{}},{"cell_type":"code","source":"# Performing Vectorizing to crate bigram model\nvect = CountVectorizer(ngram_range=(1,2)).fit(text_df['text'])","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:36.801568Z","iopub.execute_input":"2023-07-21T22:46:36.802359Z","iopub.status.idle":"2023-07-21T22:46:37.419658Z","shell.execute_reply.started":"2023-07-21T22:46:36.802326Z","shell.execute_reply":"2023-07-21T22:46:37.418664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Getting Features\nfeature_names = vect.get_feature_names_out()\nprint(\"Number of features: {}\\n\".format(len(feature_names)))\nprint(\"First 20 features:\\n {}\".format(feature_names[:20]))","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:37.420966Z","iopub.execute_input":"2023-07-21T22:46:37.421307Z","iopub.status.idle":"2023-07-21T22:46:37.517041Z","shell.execute_reply.started":"2023-07-21T22:46:37.421277Z","shell.execute_reply":"2023-07-21T22:46:37.515906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<h1 class=\"alert alert-block alert-info\" style=\"text-align:center; font-size:30px\">Model Development</h1>","metadata":{}},{"cell_type":"code","source":"#seperating Independent and Depentent Variables and tranform X data\nX = text_df['text']\nY = text_df['sentiment']\nX = vect.transform(X)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:37.518714Z","iopub.execute_input":"2023-07-21T22:46:37.519087Z","iopub.status.idle":"2023-07-21T22:46:37.868064Z","shell.execute_reply.started":"2023-07-21T22:46:37.519054Z","shell.execute_reply":"2023-07-21T22:46:37.867026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting data with test 20%\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:37.873473Z","iopub.execute_input":"2023-07-21T22:46:37.873824Z","iopub.status.idle":"2023-07-21T22:46:37.883548Z","shell.execute_reply.started":"2023-07-21T22:46:37.873795Z","shell.execute_reply":"2023-07-21T22:46:37.882664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking shape of train and test data\nprint(\"Size of x_train:\", (x_train.shape))\nprint(\"Size of y_train:\", (y_train.shape))\nprint(\"Size of x_test:\", (x_test.shape))\nprint(\"Size of y_test:\", (y_test.shape))","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:37.885072Z","iopub.execute_input":"2023-07-21T22:46:37.886006Z","iopub.status.idle":"2023-07-21T22:46:37.893245Z","shell.execute_reply.started":"2023-07-21T22:46:37.885919Z","shell.execute_reply":"2023-07-21T22:46:37.892476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\n#Training logisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\nlogreg_pred = logreg.predict(x_test)\nlogreg_acc = accuracy_score(logreg_pred, y_test)\nprint(\"Test accuracy: {:.2f}%\".format(logreg_acc*100))","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:37.894634Z","iopub.execute_input":"2023-07-21T22:46:37.895270Z","iopub.status.idle":"2023-07-21T22:46:48.596603Z","shell.execute_reply.started":"2023-07-21T22:46:37.895239Z","shell.execute_reply":"2023-07-21T22:46:48.595267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confusion matrix\nprint(confusion_matrix(y_test, logreg_pred))\nprint(\"\\n\")\nprint(classification_report(y_test, logreg_pred))","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:48.598605Z","iopub.execute_input":"2023-07-21T22:46:48.605701Z","iopub.status.idle":"2023-07-21T22:46:48.734073Z","shell.execute_reply.started":"2023-07-21T22:46:48.605613Z","shell.execute_reply":"2023-07-21T22:46:48.732779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"style.use('classic')\ncm = confusion_matrix(y_test, logreg_pred, labels=logreg.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels=logreg.classes_)\ndisp.plot()","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:48.735137Z","iopub.execute_input":"2023-07-21T22:46:48.735447Z","iopub.status.idle":"2023-07-21T22:46:49.048295Z","shell.execute_reply.started":"2023-07-21T22:46:48.735420Z","shell.execute_reply":"2023-07-21T22:46:49.047137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 class=\"alert alert-block alert-info\" style=\"text-align:center; font-size:30px\">Tuning Model</h1>","metadata":{}},{"cell_type":"code","source":"#Lets perform Hyper-Parameter to modulate performance of model\n\nparam_grid={'C':[0.001, 0.01, 0.1, 1, 10]}                  #Taking random  alpha values\ngrid = GridSearchCV(LogisticRegression(), param_grid)\ngrid.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:46:49.049917Z","iopub.execute_input":"2023-07-21T22:46:49.050982Z","iopub.status.idle":"2023-07-21T22:49:13.365748Z","shell.execute_reply.started":"2023-07-21T22:46:49.050915Z","shell.execute_reply":"2023-07-21T22:49:13.364200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Best parameters:\", grid.best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T22:59:44.922538Z","iopub.execute_input":"2023-07-21T22:59:44.923090Z","iopub.status.idle":"2023-07-21T22:59:44.929424Z","shell.execute_reply.started":"2023-07-21T22:59:44.923045Z","shell.execute_reply":"2023-07-21T22:59:44.928328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = grid.predict(x_test)\nlogreg_acc = accuracy_score(y_pred, y_test)\nprint(\"Test accuracy: {:.2f}%\".format(logreg_acc*100))","metadata":{"execution":{"iopub.status.busy":"2023-07-21T23:02:42.778492Z","iopub.execute_input":"2023-07-21T23:02:42.779587Z","iopub.status.idle":"2023-07-21T23:02:42.792277Z","shell.execute_reply.started":"2023-07-21T23:02:42.779546Z","shell.execute_reply":"2023-07-21T23:02:42.791099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# we can see increase in accurancy by impementing hyperparameter","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:black solid;padding: 15px;background-color:lightgreen;font-size:110%;text-align:left\">\n<div style=\"font-family:Georgia;background-color:'#DEB887'; padding:30px; font-size:25px\">\n\n<h1 style=\"color:black;font-size:20px;font-family:Georgia;text-align:center;\">üë®‚Äçüíª<strong>Thank you for Joining, Happy Kaggling</strong>üë®‚Äçüíª</h1>","metadata":{}}]}